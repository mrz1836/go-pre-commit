# ------------------------------------------------------------------------------------
#  Test Suite (Reusable Workflow) (GoFortress)
#
#  Purpose: Run the main Go test suite across multiple Go versions and operating
#  systems, including unit tests, race detection, coverage, and fuzz tests.
#
#  Maintainer: @mrz1836
#
# ------------------------------------------------------------------------------------

name: GoFortress (Go Test Suite)

on:
  workflow_call:
    inputs:
      env-json:
        description: "JSON string of environment variables"
        required: true
        type: string
      test-matrix:
        description: "Test matrix JSON"
        required: true
        type: string
      primary-runner:
        description: "Primary runner OS"
        required: true
        type: string
      go-primary-version:
        description: "Primary Go version"
        required: true
        type: string
      go-secondary-version:
        description: "Secondary Go version"
        required: true
        type: string
      code-coverage-enabled:
        description: "Whether code coverage is enabled"
        required: true
        type: string
      coverage-provider:
        description: "Coverage service provider (internal or codecov)"
        required: false
        type: string
        default: "internal"
      race-detection-enabled:
        description: "Whether race detection is enabled"
        required: true
        type: string
      fuzz-testing-enabled:
        description: "Whether fuzz testing is enabled"
        required: true
        type: string
    secrets:
      github-token:
        description: "GitHub token for API access"
        required: true
      CODECOV_TOKEN:
        description: "Codecov token for uploading coverage (required when coverage-provider is codecov)"
        required: false

# Security: Restrictive default permissions with job-level overrides for least privilege access
permissions:
  contents: read

jobs:
  # ----------------------------------------------------------------------------------
  # Testing Matrix for Go (Parallel)
  # ----------------------------------------------------------------------------------
  test-go:
    name: 🧪 Test (${{ matrix.name }})
    timeout-minutes: 30 # Prevent hung tests
    permissions:
      contents: write # Read repository content for testing
    strategy:
      fail-fast: true
      matrix: ${{ fromJSON(inputs.test-matrix) }}
    runs-on: ${{ matrix.os }}

    steps:
      # ————————————————————————————————————————————————————————————————
      # Checkout code (required for local actions)
      # ————————————————————————————————————————————————————————————————
      - name: 📥 Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      # ————————————————————————————————————————————————————————————————
      # Parse environment variables
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Parse environment variables
        uses: ./.github/actions/parse-env
        with:
          env-json: ${{ inputs.env-json }}

      # ————————————————————————————————————————————————————————————————
      # Setup Go with caching and version management
      # ————————————————————————————————————————————————————————————————
      - name: 🏗️ Setup Go with Cache
        id: setup-go-test
        uses: ./.github/actions/setup-go-with-cache
        with:
          go-version: ${{ matrix.go-version }}
          matrix-os: ${{ matrix.os }}
          go-primary-version: ${{ inputs.go-primary-version }}
          go-secondary-version: ${{ inputs.go-secondary-version }}

      # ————————————————————————————————————————————————————————————————
      # Setup MAGE-X (required for magex test commands)
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Setup MAGE-X
        uses: ./.github/actions/setup-magex
        with:
          magex-version: ${{ env.MAGE_X_VERSION }}
          runner-os: ${{ matrix.os }}

      # ————————————————————————————————————————————————————————————————
      # Start test timer
      # ————————————————————————————————————————————————————————————————
      - name: ⏱️ Start test timer
        id: test-timer
        run: |
          echo "test-start=$(date +%s)" >> $GITHUB_OUTPUT

      # ————————————————————————————————————————————————————————————————
      # Detect test output mode
      # ————————————————————————————————————————————————————————————————
      - name: 🔍 Detect test output mode
        id: detect-mode
        run: |
          # Count tests to determine appropriate output mode
          TEST_COUNT=$(find . -name '*_test.go' \
            -not -path './vendor/*' \
            -not -path './third_party/*' \
            -not -path './testdata/*' \
            -exec grep -hE '^\s*func (\([^)]+\) )?Test[A-Z0-9_]' {} + | wc -l | xargs)
          TEST_COUNT=${TEST_COUNT:-0}

          OUTPUT_MODE="${TEST_OUTPUT_MODE:-SMART}"
          THRESHOLD="${TEST_OUTPUT_SMART_THRESHOLD:-500}"

          echo "📊 Found $TEST_COUNT tests"
          echo "🎛️ Configured mode: $OUTPUT_MODE"
          echo "🎯 Smart threshold: $THRESHOLD tests"

          if [[ "$OUTPUT_MODE" == "SMART" ]]; then
            if [[ "$TEST_COUNT" -gt "$THRESHOLD" ]]; then
              DETECTED_MODE="FAILURES_ONLY"
              echo "🎯 Using FAILURES_ONLY mode for $TEST_COUNT tests"
            else
              DETECTED_MODE="FULL"
              echo "📝 Using FULL mode for $TEST_COUNT tests"
            fi
          else
            DETECTED_MODE="$OUTPUT_MODE"
            echo "🔧 Using configured mode: $DETECTED_MODE"
          fi

          echo "detected-mode=$DETECTED_MODE" >> $GITHUB_OUTPUT
          echo "test-count=$TEST_COUNT" >> $GITHUB_OUTPUT
          echo "DETECTED_OUTPUT_MODE=$DETECTED_MODE" >> $GITHUB_ENV
          echo "TEST_COUNT=$TEST_COUNT" >> $GITHUB_ENV

      # ————————————————————————————————————————————————————————————————
      # Define robust failure detection functions
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Define failure detection functions
        run: |
          # Define reusable function for robust test failure detection
          cat > test-failure-functions.sh << 'DETECTION_FUNCTIONS_EOF'
          #!/bin/bash

          # Robust test failure detection function
          detect_test_failures() {
            local output_file="$1"
            local exit_code="${2:-0}"
            local mode="${3:-text}"
            local failures_file="${4:-test-failures.txt}"

            echo "🔍 Detecting test failures with exit code: $exit_code, mode: $mode"

            # Primary check: exit code indicates failure
            if [[ "$exit_code" -ne 0 ]]; then
              echo "❌ Exit code $exit_code indicates test failure"

              if [[ -f "$output_file" ]]; then
                case "$mode" in
                  "json")
                    # Enhanced JSON-based detection
                    detect_failures_from_json "$output_file" "$failures_file"
                    ;;
                  "text"|*)
                    # Enhanced text-based detection
                    detect_failures_from_text "$output_file" "$failures_file"
                    ;;
                esac

                # Count detected failures
                if [[ -f "$failures_file" ]]; then
                  DETECTED_FAILURES=$(wc -l < "$failures_file" 2>/dev/null || echo "0")
                  echo "📊 Detected $DETECTED_FAILURES specific failures"
                  return $DETECTED_FAILURES
                fi
              else
                echo "⚠️ Output file '$output_file' not found, relying on exit code"
                echo "Exit code indicates failure but no output file found" > "$failures_file"
                return 1
              fi
            else
              echo "✅ Exit code 0 indicates success"
              touch "$failures_file"  # Create empty failures file
              return 0
            fi
          }

          # Smart and efficient JSON failure detection
          detect_failures_from_json() {
            local json_file="$1"
            local failures_file="$2"

            echo "🔍 Using smart JSON-based failure detection on $json_file"

            # Quick JSON validation (< 0.1s) - check if file contains JSON test output
            if ! grep -q '^{.*"Action"' "$json_file" 2>/dev/null; then
              echo "⚠️ No JSON content detected, using text fallback"
              detect_failures_from_text "$json_file" "$failures_file"
              return
            fi

            echo "✅ JSON content detected, processing efficiently..."

            # Fast single-pass JSON extraction (< 1s for 10K lines)
            # Filter JSON lines and parse in one pass - eliminates 2-minute hang
            grep '^{' "$json_file" 2>/dev/null | \
              jq -r 'select(.Action == "fail") | "--- FAIL: \(.Test) (\(.Package))"' \
              2>/dev/null > "$failures_file"

            local failure_count
            failure_count=$(wc -l < "$failures_file" 2>/dev/null | tr -d '\n\r' | xargs)
            [[ "$failure_count" =~ ^[0-9]+$ ]] || failure_count=0

            if [[ "$failure_count" -gt 0 ]]; then
              echo "✅ Found $failure_count test failures in JSON output"
              return 0
            else
              echo "ℹ️ No failures detected in JSON output"
              return 0
            fi
          }

          # Enhanced text-based failure detection
          detect_failures_from_text() {
            local text_file="$1"
            local failures_file="$2"
            local detailed_failures_file="${failures_file%.txt}-detailed.txt"

            echo "🔍 Using enhanced text-based failure detection on $text_file"

            # Enhanced pattern matching for various failure formats
            # Patterns handle: FAIL, --- FAIL, --FAIL, [FAIL], FAIL:, etc.
            local patterns=(
              '^FAIL[[:space:]:]'
              '^---[[:space:]]*FAIL'
              '^--[[:space:]]*FAIL'
              '^\[?FAIL\]?[[:space:]:.]'
              '--- FAIL:'
              'FAIL[[:space:]]*:'
              '^[[:space:]]*FAIL[[:space:]]'
            )

            local temp_failures=$(mktemp)
            local temp_detailed=$(mktemp)
            local found_any=false

            # First pass: Find all failure lines and capture context
            for pattern in "${patterns[@]}"; do
              if grep -E -A 15 "$pattern" "$text_file" >> "$temp_detailed" 2>/dev/null; then
                found_any=true
                # Also capture just the failure line for the summary
                grep -E "$pattern" "$text_file" >> "$temp_failures" 2>/dev/null || true
              fi
            done

            if [[ "$found_any" == "true" ]]; then
              # Process the detailed failures to create structured output
              echo "🔍 Processing detailed failure output..."

              # Create a structured detailed failures file with error messages
              awk '
                BEGIN {
                  current_test = ""
                  capture_output = 0
                  output_buffer = ""
                }
                /^(FAIL|---.*FAIL|--.*FAIL|\[?FAIL\]?)/ {
                  # If we were capturing output, save it
                  if (current_test != "" && output_buffer != "") {
                    print "TEST:" current_test
                    print "ERROR:" output_buffer
                    print "---SEPARATOR---"
                  }

                  # Start new test capture
                  current_test = $0
                  output_buffer = ""
                  capture_output = 1
                  next
                }
                capture_output == 1 && /^[[:space:]]*$/ {
                  # Empty line might end the error context
                  if (length(output_buffer) > 100) capture_output = 0
                  next
                }
                capture_output == 1 && !/^(PASS|ok |FAIL|---.*FAIL|--.*FAIL)/ {
                  # Capture error output lines
                  if (output_buffer == "") {
                    output_buffer = $0
                  } else {
                    output_buffer = output_buffer "\n" $0
                  }
                  # Stop if we have captured enough context
                  if (length(output_buffer) > 1500) capture_output = 0
                }
                /^(PASS|ok )/ && capture_output == 1 {
                  # Another test started, stop capturing
                  capture_output = 0
                }
                END {
                  # Save the last test if we were capturing
                  if (current_test != "" && output_buffer != "") {
                    print "TEST:" current_test
                    print "ERROR:" output_buffer
                    print "---SEPARATOR---"
                  }
                }
              ' "$temp_detailed" > "$detailed_failures_file" 2>/dev/null || true

              # Remove duplicates and sort for the summary file
              sort -u "$temp_failures" > "$failures_file"
              echo "✅ Text parsing found $(wc -l < "$failures_file") unique failures with detailed error messages"

              # Clean up
              rm -f "$temp_failures" "$temp_detailed"
              return 0
            fi

            # Fallback: look for any error indicators
            echo "⚠️ Standard failure patterns not found, checking for error indicators"
            local error_patterns=(
              'panic:'
              'fatal error:'
              'build failed'
              'compilation error'
              'timeout'
              'killed'
              'error:'
            )

            for pattern in "${error_patterns[@]}"; do
              if grep -i -A 5 "$pattern" "$text_file" >> "$temp_detailed" 2>/dev/null; then
                found_any=true
                grep -i "$pattern" "$text_file" >> "$temp_failures" 2>/dev/null || true
              fi
            done

            if [[ "$found_any" == "true" ]]; then
              sort -u "$temp_failures" > "$failures_file"
              cp "$temp_detailed" "$detailed_failures_file" 2>/dev/null || true
              echo "⚠️ Found $(wc -l < "$failures_file") error indicators (not standard test failures)"
              rm -f "$temp_failures" "$temp_detailed"
              return 0
            fi

            rm -f "$temp_failures" "$temp_detailed"

            # If exit code indicated failure but no patterns found, create generic entry
            if [[ "${TEST_EXIT_CODE:-0}" -ne 0 ]]; then
              echo "Generic test failure (exit code ${TEST_EXIT_CODE:-0}) - pattern detection failed" > "$failures_file"
              echo "⚠️ Exit code indicates failure but no recognizable patterns found"
              return 1
            else
              touch "$failures_file"  # Create empty failures file
              echo "✅ No failures detected and exit code is 0"
              return 0
            fi
          }

          # Utility function for safe numeric validation
          sanitize_numeric() {
            local value="$1"
            value=$(echo "$value" | tr -d '\n\r' | xargs)
            if [[ "$value" =~ ^[0-9]+$ ]]; then
              echo "$value"
            else
              echo "0"
            fi
          }

          # Export functions for use in other steps
          export -f detect_test_failures
          export -f detect_failures_from_json
          export -f detect_failures_from_text
          export -f sanitize_numeric
          DETECTION_FUNCTIONS_EOF

          # Source the functions to make them available
          source test-failure-functions.sh
          echo "✅ Failure detection functions defined and loaded"

      # ————————————————————————————————————————————————————————————————
      # Run tests and coverage
      # ————————————————————————————————————————————————————————————————
      - name: 🧪 Run tests
        id: run-tests
        continue-on-error: true
        run: |
          # Sanitize inherited environment variables first
          TEST_COUNT=${TEST_COUNT:-0}
          TEST_COUNT=$(echo "$TEST_COUNT" | xargs)
          if ! [[ "$TEST_COUNT" =~ ^[0-9]+$ ]]; then
            TEST_COUNT=0
          fi
          export TEST_COUNT

          # Safely assign values to shell vars with defaults
          RACE="${{ inputs.race-detection-enabled || 'false' }}"
          COVER="${{ inputs.code-coverage-enabled || 'false' }}"
          MODE="${{ steps.detect-mode.outputs.detected-mode || 'FULL' }}"

          echo "🔍 Race Detection Enabled: $RACE"
          echo "🔍 Code Coverage Enabled: $COVER"
          echo "🎛️ Output Mode: $MODE"

          # Initialize test exit code
          TEST_EXIT_CODE=0

          # Build unified magex command with timeout and appropriate test type
          if [[ "$RACE" == "true" && "$COVER" == "true" ]]; then
            TEST_TIMEOUT="${TEST_TIMEOUT_RACE_COVER:-30m}"
            TEST_TYPE="coverrace"
            echo "🏁 Running tests with race detection and coverage analysis (timeout: $TEST_TIMEOUT)..."
          elif [[ "$RACE" != "true" && "$COVER" == "true" ]]; then
            TEST_TIMEOUT="${TEST_TIMEOUT_RACE_COVER:-30m}"
            TEST_TYPE="cover"
            echo "🏁 Running tests with coverage analysis (timeout: $TEST_TIMEOUT)..."
          elif [[ "$RACE" == "true" && "$COVER" != "true" ]]; then
            TEST_TIMEOUT="${TEST_TIMEOUT:-30m}"
            TEST_TYPE="race"
            echo "🏁 Running tests with race detection (timeout: $TEST_TIMEOUT)..."
          else
            TEST_TIMEOUT="${TEST_TIMEOUT_UNIT:-20m}"
            TEST_TYPE="unit"
            echo "🏁 Running tests without coverage or race detection (timeout: $TEST_TIMEOUT)..."
          fi

          # Build command with JSON flag for FAILURES_ONLY mode
          MAGEX_CMD="magex test:${TEST_TYPE} -timeout $TEST_TIMEOUT"
          if [[ "$MODE" == "FAILURES_ONLY" ]]; then
            MAGEX_CMD="$MAGEX_CMD -json"
          fi

          echo "🔧 Running: $MAGEX_CMD (timeout: $TEST_TIMEOUT)"

          # Pre-execution diagnostic info for better visibility
          PACKAGE_COUNT=$(find . -name '*.go' -not -path './vendor/*' -not -path './third_party/*' | xargs dirname | sort -u | wc -l | xargs)
          PACKAGE_COUNT=${PACKAGE_COUNT:-0}
          echo "🚀 Starting test execution:"
          echo "   • Total tests: $TEST_COUNT"
          echo "   • Test packages: $PACKAGE_COUNT"
          echo "   • Test mode: $TEST_TYPE"
          echo "   • Output mode: $MODE"
          ESTIMATED_TIME=$(( ($TEST_COUNT + 49) / 50 ))
          echo "   • Estimated time: $ESTIMATED_TIME minutes (based on ~50 tests/minute)"
          echo "   • Timeout: $TEST_TIMEOUT"
          echo ""

          START_TIME=$(date +%s)
          export START_TIME

          # Execute based on detected mode with simplified processing
          set +e  # Don't exit on error to capture exit code properly
          if [[ "$MODE" == "FULL" ]]; then
            echo "📝 Using FULL output mode - showing all test output"
            echo "🔍 Executing: $MAGEX_CMD"
            $MAGEX_CMD 2>&1 | tee test-output.log
            TEST_EXIT_CODE=${PIPESTATUS[0]}
            echo "🔍 Magex command exit code: $TEST_EXIT_CODE"

            # Extract failures for summary (even in full mode) using robust detection
            if [[ $TEST_EXIT_CODE -ne 0 ]]; then
              source test-failure-functions.sh 2>/dev/null || true
              detect_failures_from_text "test-output.log" "test-failures.txt" || true
            fi

          else
            echo "🎯 Using FAILURES_ONLY mode with optimized JSON processing"
            echo "⏳ Tests starting... (this may take several minutes)"
            echo "📝 Output will show failures and key events only"
            echo ""

            # Start background progress monitor
            (
              MONITOR_PID=$$
              PACKAGES_PROCESSED=0
              while sleep 30; do
                if ! kill -0 $MONITOR_PID 2>/dev/null; then break; fi
                ELAPSED=$(($(date +%s) - START_TIME))
                MINUTES=$((ELAPSED / 60))
                SECONDS=$((ELAPSED % 60))

                # Count completed tests by checking for individual test passes
                if [[ -f test-raw-output.log ]]; then
                  # Count unique test pass completions (not all pass events)
                  CURRENT_TESTS=$(grep -c '{"Time".*"Action":"pass".*"Test":"Test.*"Package"' test-raw-output.log 2>/dev/null || echo "0")
                  # Fix: Ensure numeric value by trimming whitespace and validating
                  CURRENT_TESTS=$(echo "$CURRENT_TESTS" | tr -d '\n\r' | xargs)
                  # Ensure it's numeric, default to 0 if not
                  if ! [[ "$CURRENT_TESTS" =~ ^[0-9]+$ ]]; then
                    CURRENT_TESTS=0
                  fi
                  # Ensure PACKAGES_PROCESSED is numeric
                  if ! [[ "$PACKAGES_PROCESSED" =~ ^[0-9]+$ ]]; then
                    PACKAGES_PROCESSED=0
                  fi

                  if [[ $CURRENT_TESTS -gt $PACKAGES_PROCESSED ]]; then
                    PACKAGES_PROCESSED=$CURRENT_TESTS
                    echo "⏳ Progress update: ${MINUTES}m${SECONDS}s elapsed, ~${PACKAGES_PROCESSED}/${TEST_COUNT} tests completed"
                  else
                    echo "⏳ Still running: ${MINUTES}m${SECONDS}s elapsed, processing tests..."
                  fi
                fi
              done
            ) &
            MONITOR_PID=$!

            # Optimized single-pass JSON processing with real-time progress
            # Run magex with real-time display and correct exit code capture
            echo "🔍 Executing: $MAGEX_CMD"

            # Separate JSON output from error messages for efficient processing
            # Save all output first, then separate JSON from messages
            $MAGEX_CMD 2> >(tee test-stderr.log >&2) | \
              tee test-raw-output-all.log | \
              tee >(grep '^{' > test-raw-output.log 2>/dev/null || true) | \
              tee >(grep -v '^{' > test-messages.log 2>/dev/null || true) |
              (jq -r --unbuffered '
                # Efficiently process each JSON line with progress indicators
                if .Action == "run" then
                  # Package started - show progress
                  "📦 Testing: \(.Package | split("/") | .[-1] // .[-2] // .)"
                elif .Action == "output" and .Test == null then
                  # Package-level output (build messages, etc.)
                  .Output // ""
                elif .Action == "fail" then
                  # Failed test - immediate visibility
                  "❌ FAIL: \(.Test) (\(.Package | split("/") | .[-1] // .[-2] // .))"
                elif .Action == "pass" and (.Test | test("^Test")) then
                  # Only show individual test passes occasionally to avoid spam
                  if (now | floor) % 5 == 0 then
                    "✅ PASS: \(.Test)"
                  else
                    empty
                  end
                else
                  # Skip other JSON events for cleaner output
                  empty
                end
              ' 2>/dev/null || {
                echo "⚠️ JSON processing failed, showing messages and errors:"
                # Show separated non-JSON messages when jq fails
                [[ -f test-messages.log ]] && cat test-messages.log || cat test-raw-output-all.log
              }) | tee test-output.log > test-output-tail.log

            # Capture magex exit code (PIPESTATUS[0] = magex, not jq)
            TEST_EXIT_CODE=${PIPESTATUS[0]}
            echo "🔍 Magex command exit code: $TEST_EXIT_CODE"

            # Kill the progress monitor
            kill $MONITOR_PID 2>/dev/null || true

            echo ""
            echo "✅ Test execution completed"

            # Extract failures with enhanced JSON processing and robust fallback
            if [[ $TEST_EXIT_CODE -ne 0 ]]; then
              echo "🔍 Extracting failure information using robust detection..."

              # Source failure detection functions
              source test-failure-functions.sh 2>/dev/null || true

              # Use robust JSON-based detection
              detect_failures_from_json "test-raw-output.log" "test-failures.txt" || {
                echo "⚠️ JSON detection failed, using exit code indicator"
                echo "Test failure detected (exit code $TEST_EXIT_CODE) - JSON parsing failed" > test-failures.txt
              }

              # Create enhanced failure summary with efficient single-pass processing
              echo "🔍 Creating failure summary..."

              # Extract all failure records with error messages in one optimized pass
              if grep -q '^{.*"Action"' test-raw-output.log 2>/dev/null; then
                # Process JSON output to capture both failures AND their error messages
                echo "🔍 Extracting failures with error messages from JSON output..."

                # Create enhanced failure extraction that combines fail events with their output events
                grep '^{' test-raw-output.log 2>/dev/null | jq -s '
                  # Group all events by Package and Test
                  group_by(.Package + ":" + (.Test // "")) |

                  # Process each package+test group
                  map(
                    . as $group |
                    $group[0] as $first |

                    # Check if this group has a fail event
                    if ($group | map(select(.Action == "fail")) | length > 0) then
                      # Extract the fail event and all associated output
                      {
                        Package: $first.Package,
                        Test: $first.Test,
                        Elapsed: ($group | map(select(.Action == "fail")) | .[0].Elapsed // null),
                        # Combine all output events for this test
                        Output: ($group | map(select(.Action == "output" and .Test != null)) | map(.Output // "") | join(""))
                      }
                    else
                      empty
                    end
                  ) |

                  # Filter out empty results and group by package
                  map(select(.Test != null and .Test != "")) |
                  group_by(.Package) |
                  map({
                    Package: .[0].Package,
                    failures: map({
                      Test: .Test,
                      Elapsed: .Elapsed,
                      Output: (.Output | if length > 2000 then .[0:2000] + "..." else . end),
                      Package: .Package
                    })
                  })
                ' 2>/dev/null > test-failures-summary.json && \
                  echo "✅ Enhanced JSON failure summary with error messages created" || {
                    echo "⚠️ Advanced JSON processing failed, trying simpler approach..."
                    # Fallback: simpler processing
                    grep '^{' test-raw-output.log 2>/dev/null | \
                      jq -c 'select(.Action == "fail")' 2>/dev/null | \
                      jq -s 'group_by(.Package) |
                        map({
                          Package: .[0].Package,
                          failures: map({Test: .Test, Elapsed: .Elapsed, Output: "", Package: .Package})
                        })' > test-failures-summary.json 2>/dev/null || echo "[]" > test-failures-summary.json
                    echo "⚠️ Using basic format without error messages"
                  }
              else
                # Create summary from text failures if no JSON
                if [[ -s test-failures.txt ]]; then
                  echo "📋 Creating summary from text failures"
                  echo '[{"Package": "unknown", "failures": [' > test-failures-summary.json
                  awk '{print "{\"Test\": \"" $0 "\", \"Elapsed\": null}"}' test-failures.txt | \
                    paste -sd ',' - >> test-failures-summary.json 2>/dev/null || true
                  echo ']}]' >> test-failures-summary.json
                  echo "✅ Basic failure summary created"
                else
                  echo "[]" > test-failures-summary.json
                fi
              fi
            else
              echo "ℹ️ No test failures detected (exit code 0)"
              touch test-failures.txt
              echo "[]" > test-failures-summary.json
            fi
          fi
          set -e  # Re-enable exit on error

          # Final execution summary with timing
          END_TIME=$(date +%s)
          TOTAL_DURATION=$((END_TIME - START_TIME))
          MINUTES=$((TOTAL_DURATION / 60))
          SECONDS=$((TOTAL_DURATION % 60))

          # Validate test success based on actual results vs exit code
          echo "🔍 Validating test results..."
          ACTUAL_FAILURES=0
          if [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
            ACTUAL_FAILURES=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
            ACTUAL_FAILURES=$(echo "$ACTUAL_FAILURES" | tr -d '\n\r' | xargs)
            [[ "$ACTUAL_FAILURES" =~ ^[0-9]+$ ]] || ACTUAL_FAILURES=0
          fi

          echo "📊 Test validation results:"
          echo "   • Original exit code: $TEST_EXIT_CODE"
          echo "   • Detected failures: $ACTUAL_FAILURES"

          # If exit code indicates failure but no actual failures found, correct it
          if [[ $TEST_EXIT_CODE -ne 0 ]] && [[ $ACTUAL_FAILURES -eq 0 ]]; then
            echo "⚠️ Exit code indicates failure but no test failures detected - correcting exit code"
            echo "🔧 This suggests the exit code issue was from JSON processing, not actual test failures"
            TEST_EXIT_CODE=0
            echo "   • Corrected exit code: $TEST_EXIT_CODE"
          elif [[ $TEST_EXIT_CODE -eq 0 ]] && [[ $ACTUAL_FAILURES -gt 0 ]]; then
            echo "⚠️ Exit code indicates success but test failures were detected - correcting exit code"
            TEST_EXIT_CODE=1
            echo "   • Corrected exit code: $TEST_EXIT_CODE"
          else
            echo "✅ Exit code and test results are consistent"
          fi

          # Store the validated exit code and mode for later steps
          echo "TEST_EXIT_CODE=$TEST_EXIT_CODE" >> $GITHUB_ENV
          echo "test-exit-code=$TEST_EXIT_CODE" >> $GITHUB_OUTPUT
          echo "output-mode=$MODE" >> $GITHUB_OUTPUT

          if [[ $TEST_EXIT_CODE -eq 0 ]]; then
            echo ""
            echo "🎉 All tests completed successfully!"
            echo "   • Total time: ${MINUTES}m${SECONDS}s"
            echo "   • Tests executed: $TEST_COUNT"
            if [[ $TOTAL_DURATION -gt 0 ]]; then
              AVERAGE_SPEED=$(( (TEST_COUNT * 60) / TOTAL_DURATION ))
              echo "   • Average speed: $AVERAGE_SPEED tests/minute"
            fi
          else
            echo ""
            echo "❌ Tests failed with exit code $TEST_EXIT_CODE"
            echo "   • Total time: ${MINUTES}m${SECONDS}s"
            echo "   • Tests executed: $TEST_COUNT"
            if [[ -f test-failures.txt ]]; then
              FAILURE_COUNT=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
              echo "   • Failed tests: $FAILURE_COUNT"
              if [[ $TEST_COUNT -gt 0 ]]; then
                SUCCESS_RATE=$(( (TEST_COUNT - FAILURE_COUNT) * 100 / TEST_COUNT ))
                echo "   • Success rate: $SUCCESS_RATE%"
              fi
            fi
          fi

      # ————————————————————————————————————————————————————————————————
      # Fix coverage file naming (normalize to coverage.txt for downstream processing)
      # Handles magex commands (coverage_0.txt output)
      # ————————————————————————————————————————————————————————————————
      - name: 🔄 Normalize coverage file name
        if: inputs.code-coverage-enabled == 'true'
        run: |
          echo "🔍 Looking for coverage files..."
          ls -la coverage*.txt 2>/dev/null || true

          if [ -f coverage_0.txt ]; then
            cp coverage_0.txt coverage.txt
            echo "✅ Copied coverage_0.txt to coverage.txt"
            echo "📊 Coverage file size: $(wc -c < coverage.txt) bytes"
          elif [ -f coverage.txt ]; then
            echo "✅ Coverage file already exists as coverage.txt"
            echo "📊 Coverage file size: $(wc -c < coverage.txt) bytes"
          else
            echo "❌ No coverage file found!"
            echo "📋 Files in current directory:"
            ls -la *.txt *.out 2>/dev/null | head -10 || true
            echo "📋 Searching for any coverage-related files:"
            find . -maxdepth 1 -name "*cover*" -type f 2>/dev/null || true
          fi

      # ————————————————————————————————————————————————————————————————
      # Enhanced test failure analysis and reporting
      # ————————————————————————————————————————————————————————————————
      - name: 🚨 Create Test Failure Summary
        if: failure()
        run: |
          OUTPUT_MODE="${{ steps.run-tests.outputs.output-mode || 'FULL' }}"
          TEST_COUNT="${{ steps.detect-mode.outputs.test-count || '0' }}"

          echo "## 🚨 Test Failures - ${{ matrix.name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **OS**: ${{ matrix.os }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Go Version**: ${{ matrix.go-version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Race Detection**: ${{ inputs.race-detection-enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Enabled**: ${{ inputs.code-coverage-enabled }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Total Tests**: $TEST_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **Output Mode**: $OUTPUT_MODE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Choose appropriate analysis based on output mode with robust detection
          # Source failure detection functions
          source test-failure-functions.sh 2>/dev/null || true

          if [[ "$OUTPUT_MODE" == "FULL" ]]; then
            # Enhanced analysis for FULL mode using robust detection
            OUTPUT_FILE="test-output.log"
            if [ -f "$OUTPUT_FILE" ]; then
              # Use robust failure counting from existing failure file or detect from output
              if [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
                FAIL_COUNT=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
                echo "🔍 Using robust failure count: $FAIL_COUNT"
              else
                # Fallback: detect from output file
                detect_failures_from_text "$OUTPUT_FILE" "temp-failures.txt" || true
                FAIL_COUNT=$(wc -l < temp-failures.txt 2>/dev/null || echo "0")
                rm -f temp-failures.txt
                echo "⚠️ Fallback failure detection used: $FAIL_COUNT"
              fi

              # Enhanced panic detection with numeric validation
              PANIC_COUNT=$(grep -c -E "panic:|fatal error:|runtime error:" "$OUTPUT_FILE" 2>/dev/null || echo "0")
              PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
              [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0

              PASS_COUNT=$(grep -c -E "^(PASS|ok[[:space:]]|---[[:space:]]*PASS)" "$OUTPUT_FILE" 2>/dev/null || echo "0")
              PASS_COUNT=$(echo "$PASS_COUNT" | tr -d '\n\r' | xargs)
              [[ "$PASS_COUNT" =~ ^[0-9]+$ ]] || PASS_COUNT=0

              echo "- **Passed Tests**: $PASS_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "- **Failed Tests**: $FAIL_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "- **Panics**: $PANIC_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY

              if [[ "$FAIL_COUNT" -gt 0 ]] && [[ -f test-failures.txt ]]; then
                echo "### 🔍 Failed Tests" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                head -${TEST_FAILURE_DETAIL_COUNT:-20} test-failures.txt >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY

                # Show detailed error messages if available from FULL mode
                if [[ -f test-failures-detailed.txt ]] && [[ -s test-failures-detailed.txt ]]; then
                  echo "### 📝 Test Error Messages" >> $GITHUB_STEP_SUMMARY
                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY

                  # Parse and display the structured error output
                  awk '
                    /^TEST:/ {
                      test_name = substr($0, 6)  # Remove "TEST:" prefix
                      getline
                      if (/^ERROR:/ && length($0) > 6) {
                        error_msg = substr($0, 7)  # Remove "ERROR:" prefix
                        print "❌ " test_name
                        print error_msg
                        print ""
                      }
                    }
                  ' test-failures-detailed.txt | head -c 3000 >> $GITHUB_STEP_SUMMARY

                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                  echo "" >> $GITHUB_STEP_SUMMARY
                fi
              fi

              if [[ "$PANIC_COUNT" -gt 0 ]]; then
                echo "### 🚨 Panic/Error Summary" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                # Enhanced panic/error detection patterns
                grep -A 2 -B 1 -E "panic:|fatal error:|runtime error:" "$OUTPUT_FILE" | head -20 >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "⚠️ Test output log not found" >> $GITHUB_STEP_SUMMARY
            fi

          else
            # Enhanced analysis for FAILURES_ONLY mode
            if [[ -f test-failures-summary.json ]] && [[ -s test-failures-summary.json ]]; then
              # Extract detailed failure information
              TOTAL_FAILURES=$(jq '[.[] | .failures | length] | add // 0' test-failures-summary.json 2>/dev/null || echo "0")
              AFFECTED_PACKAGES=$(jq 'length' test-failures-summary.json 2>/dev/null || echo "0")

              echo "- **Failed Tests**: $TOTAL_FAILURES" >> $GITHUB_STEP_SUMMARY
              echo "- **Affected Packages**: $AFFECTED_PACKAGES" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY

              # Show package-level summary
              if [[ "$AFFECTED_PACKAGES" -gt 0 ]]; then
                echo "### 📦 Package-Level Failure Summary" >> $GITHUB_STEP_SUMMARY
                jq -r '.[] | "- **\(.Package | split("/") | .[-1] // .[-2] // .)**: \(.failures | length) failure(s)"' \
                  test-failures-summary.json >> $GITHUB_STEP_SUMMARY 2>/dev/null || true
                echo "" >> $GITHUB_STEP_SUMMARY

                # Show detailed failed tests (limited)
                echo "### 🔍 Failed Tests Details" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                jq -r '.[] as $parent | $parent.failures[] | "\(.Test) (package: \($parent.Package | split("/") | .[-1] // .[-2] // .), duration: \(.Elapsed // "unknown")s)"' \
                  test-failures-summary.json 2>/dev/null | head -${TEST_FAILURE_DETAIL_COUNT:-50} >> $GITHUB_STEP_SUMMARY || true
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY

                # Show detailed error messages from JSON mode
                ERROR_OUTPUTS=$(jq -r '.[] as $package | $package.failures[] | select(.Output != "" and .Output != null) | "❌ \(.Test) (\($package.Package | split("/") | .[-1] // .[-2] // .))\n\(.Output)\n"' test-failures-summary.json 2>/dev/null | head -c 4000)
                if [[ -n "$ERROR_OUTPUTS" ]]; then
                  echo "" >> $GITHUB_STEP_SUMMARY
                  echo "### 📝 Test Error Messages" >> $GITHUB_STEP_SUMMARY
                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                  echo "$ERROR_OUTPUTS" >> $GITHUB_STEP_SUMMARY
                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                  echo "" >> $GITHUB_STEP_SUMMARY
                else
                  # Fallback: show basic error details if structured output not available
                  BASIC_ERROR_OUTPUTS=$(jq -r '.[] | select(.Output != "") | .Output' test-failures-summary.json 2>/dev/null | head -c 2000)
                  if [[ -n "$BASIC_ERROR_OUTPUTS" ]]; then
                    echo "" >> $GITHUB_STEP_SUMMARY
                    echo "### 📝 Error Details" >> $GITHUB_STEP_SUMMARY
                    echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                    echo "$BASIC_ERROR_OUTPUTS" >> $GITHUB_STEP_SUMMARY
                    echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                    echo "" >> $GITHUB_STEP_SUMMARY
                  fi
                fi
              fi

            elif [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
              # Fallback to simple text analysis
              FAIL_COUNT=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
              echo "- **Failed Tests**: $FAIL_COUNT" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY

              if [[ "$FAIL_COUNT" -gt 0 ]]; then
                echo "### 🔍 Failed Tests" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                head -${TEST_FAILURE_DETAIL_COUNT:-20} test-failures.txt >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

                # Show detailed error messages if available from FULL mode
                if [[ -f test-failures-detailed.txt ]] && [[ -s test-failures-detailed.txt ]]; then
                  echo "" >> $GITHUB_STEP_SUMMARY
                  echo "### 📝 Test Error Messages" >> $GITHUB_STEP_SUMMARY
                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY

                  # Parse and display the structured error output
                  awk '
                    /^TEST:/ {
                      test_name = substr($0, 6)  # Remove "TEST:" prefix
                      getline
                      if (/^ERROR:/ && length($0) > 6) {
                        error_msg = substr($0, 7)  # Remove "ERROR:" prefix
                        print "❌ " test_name
                        print error_msg
                        print ""
                      }
                    }
                  ' test-failures-detailed.txt | head -c 3000 >> $GITHUB_STEP_SUMMARY

                  echo "\\`\\`\\`" >> $GITHUB_STEP_SUMMARY
                fi
              fi

            else
              echo "⚠️ No failure details available - check artifacts for complete logs" >> $GITHUB_STEP_SUMMARY
            fi

            # Check for panics in tail log if available
            if [[ -f test-output-tail.log ]]; then
              PANIC_COUNT=$(grep -c "panic:" test-output-tail.log 2>/dev/null || echo "0")
              PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
              [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0
              if [[ "$PANIC_COUNT" -gt 0 ]]; then
                echo "### 🚨 Recent Panics ($PANIC_COUNT found)" >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
                grep -A 2 -B 1 "panic:" test-output-tail.log | head -10 >> $GITHUB_STEP_SUMMARY
                echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              fi
            fi
          fi

      - name: 📋 Annotate Key Test Failures
        if: failure()
        run: |
          OUTPUT_MODE="${{ steps.run-tests.outputs.output-mode || 'FULL' }}"
          TEST_COUNT="${{ steps.detect-mode.outputs.test-count || '0' }}"
          ANNOTATION_LIMIT="${TEST_FAILURE_ANNOTATION_COUNT:-10}"

          echo "::group::📋 Test Failure Analysis ($OUTPUT_MODE mode)"

          # Source failure detection functions for robust annotation
          source test-failure-functions.sh 2>/dev/null || true

          if [[ "$OUTPUT_MODE" == "FULL" ]] && [[ -f test-output.log ]]; then
            # Enhanced annotation approach for FULL mode with robust detection

            # Use robust failure counting from existing failure file
            if [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
              FAIL_COUNT=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
              echo "🔍 Using robust failure count for annotation: $FAIL_COUNT"
            else
              # Fallback: detect from output file
              detect_failures_from_text "test-output.log" "temp-annotation-failures.txt" || true
              FAIL_COUNT=$(wc -l < temp-annotation-failures.txt 2>/dev/null || echo "0")
              echo "⚠️ Fallback failure detection for annotation: $FAIL_COUNT"
            fi

            # Enhanced panic detection with numeric validation
            PANIC_COUNT=$(grep -c -E "panic:|fatal error:|runtime error:" test-output.log 2>/dev/null || echo "0")
            PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
            [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0

            echo "::error title=Test Suite Failed::$FAIL_COUNT tests failed, $PANIC_COUNT panics/errors detected on ${{ matrix.os }} Go ${{ matrix.go-version }} ($TEST_COUNT total tests)"

            # Annotate top failed tests using robust detection
            if [[ "$FAIL_COUNT" -gt 0 ]]; then
              if [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
                head -$ANNOTATION_LIMIT test-failures.txt | while IFS= read -r line; do
                  echo "::error title=Failed Test::$line"
                done
              else
                # Fallback: use enhanced patterns
                grep -E "^(FAIL|---[[:space:]]*FAIL|--[[:space:]]*FAIL|\[?FAIL\]?)[[:space:]:.]" test-output.log | head -$ANNOTATION_LIMIT | while IFS= read -r line; do
                  echo "::error title=Failed Test::$line"
                done
              fi
            fi

            # Annotate panics/errors with enhanced patterns
            if [[ "$PANIC_COUNT" -gt 0 ]]; then
              grep -B 1 -E "panic:|fatal error:|runtime error:" test-output.log | head -3 | while IFS= read -r line; do
                echo "::error title=Test Panic/Error::$line"
              done
            fi

            # Cleanup temporary files
            rm -f temp-annotation-failures.txt

          else
            # Enhanced annotation for FAILURES_ONLY mode
            if [[ -f test-failures-summary.json ]] && [[ -s test-failures-summary.json ]]; then
              TOTAL_FAILURES=$(jq '[.[] | .failures | length] | add // 0' test-failures-summary.json 2>/dev/null || echo "0")
              AFFECTED_PACKAGES=$(jq 'length' test-failures-summary.json 2>/dev/null || echo "0")

              echo "::error title=Test Suite Failed::$TOTAL_FAILURES tests failed across $AFFECTED_PACKAGES packages on ${{ matrix.os }} Go ${{ matrix.go-version }} ($TEST_COUNT total tests)"

              # Annotate specific failed tests with package context
              jq -r '.[] as $parent | $parent.failures[] | "\(.Test) in \($parent.Package | split("/") | .[-1] // .[-2] // .)"' \
                test-failures-summary.json 2>/dev/null | head -$ANNOTATION_LIMIT | while IFS= read -r line; do
                echo "::error title=Failed Test::$line"
              done

            elif [[ -f test-failures.txt ]] && [[ -s test-failures.txt ]]; then
              # Fallback annotation
              FAIL_COUNT=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
              echo "::error title=Test Suite Failed::$FAIL_COUNT tests failed on ${{ matrix.os }} Go ${{ matrix.go-version }} ($TEST_COUNT total tests)"

              head -$ANNOTATION_LIMIT test-failures.txt | while IFS= read -r line; do
                echo "::error title=Failed Test::$line"
              done

            else
              echo "::error title=Test Suite Failed::Tests failed on ${{ matrix.os }} Go ${{ matrix.go-version }} ($TEST_COUNT total tests) - check artifacts for details"
            fi

            # Check for panics in tail log
            if [[ -f test-output-tail.log ]]; then
              PANIC_COUNT=$(grep -c "panic:" test-output-tail.log 2>/dev/null || echo "0")
              PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
              [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0
              if [[ "$PANIC_COUNT" -gt 0 ]]; then
                grep -B 1 "panic:" test-output-tail.log | head -3 | while IFS= read -r line; do
                  echo "::error title=Test Panic::$line"
                done
              fi
            fi
          fi

          echo "::endgroup::"

      # ————————————————————————————————————————————————————————————————
      # Calculate test statistics (simplified approach)
      # ————————————————————————————————————————————————————————————————
      - name: 📊 Calculate test statistics
        id: test-summary
        if: always()
        run: |
          # Get basic values
          TEST_EXIT_CODE="${{ steps.run-tests.outputs.test-exit-code || '0' }}"
          OUTPUT_MODE="${{ steps.run-tests.outputs.output-mode || 'FULL' }}"
          TEST_END=$(date +%s)
          TEST_DURATION=$((TEST_END - ${{ steps.test-timer.outputs.test-start || '0' }}))

          # Count tests and benchmarks
          TEST_COUNT=$(find . -type f -name '*_test.go' \
            -not -path './vendor/*' \
            -not -path './third_party/*' \
            -not -path './testdata/*' \
            -exec grep -hE '^\s*func (\([^)]+\) )?Test[A-Z0-9_]' {} + | wc -l | xargs)
          TEST_COUNT=${TEST_COUNT:-0}

          BENCHMARK_COUNT=$(find . -type f -name '*_test.go' \
            -not -path './vendor/*' \
            -not -path './third_party/*' \
            -exec grep -h '^func Benchmark' {} + | wc -l | xargs)
          BENCHMARK_COUNT=${BENCHMARK_COUNT:-0}

          # Count failures
          TOTAL_FAILURES=0
          if [[ -f test-failures.txt ]]; then
            TOTAL_FAILURES=$(wc -l < test-failures.txt 2>/dev/null || echo "0")
          fi

          # Calculate output size
          OUTPUT_SIZE=0
          if [[ -f test-output.log ]]; then
            OUTPUT_SIZE=$(wc -c < test-output.log 2>/dev/null || echo "0")
          fi

          # Collect Lines of Code metrics using magex
          LOC_TEST_FILES=""
          LOC_GO_FILES=""
          LOC_TOTAL=""
          LOC_DATE=$(date -u +"%Y-%m-%d")

          if command -v magex &> /dev/null; then
            echo "📊 Collecting Lines of Code metrics..."
            LOC_OUTPUT=$(magex metrics:loc 2>&1 || true)
            if [[ -n "$LOC_OUTPUT" ]]; then
              echo "📋 Raw LOC output:"
              echo "$LOC_OUTPUT"
              echo "📋 Parsing LOC data..."

              # Extract numbers from magex metrics:loc output - improved parsing
              # Format: "| Test Files | 71,476      | 2025-08-28 |" -> extract field 3, trim spaces and commas
              LOC_TEST_FILES=$(echo "$LOC_OUTPUT" | grep "Test Files" | awk -F'|' '{print $3}' | tr -d ' ,' || echo "")
              LOC_GO_FILES=$(echo "$LOC_OUTPUT" | grep "Go Files" | awk -F'|' '{print $3}' | tr -d ' ,' || echo "")
              # Format: "✅ Total lines of code: 93,418" -> extract last field after colon
              LOC_TOTAL=$(echo "$LOC_OUTPUT" | grep "Total lines of code:" | awk -F':' '{print $2}' | tr -d ' ,' || echo "")

              echo "📊 Parsed values:"
              echo "  - Test Files: '$LOC_TEST_FILES'"
              echo "  - Go Files: '$LOC_GO_FILES'"
              echo "  - Total: '$LOC_TOTAL'"

              if [[ -n "$LOC_TOTAL" ]]; then
                echo "✅ LOC collected: $LOC_TOTAL total ($LOC_TEST_FILES test, $LOC_GO_FILES go)"
              else
                echo "⚠️ LOC parsing failed - no total found"
              fi
            else
              echo "⚠️ No LOC output collected from magex"
            fi
          else
            echo "⚠️ magex not available for LOC collection"
          fi

          # Pre-compute boolean values
          TEST_PASSED=$([ "$TEST_EXIT_CODE" = "0" ] && echo "true" || echo "false")
          RACE_ENABLED="${{ inputs.race-detection-enabled == 'true' && 'true' || 'false' }}"
          COVERAGE_ENABLED="${{ inputs.code-coverage-enabled == 'true' && 'true' || 'false' }}"

          # Count affected packages from failure details
          AFFECTED_PACKAGES=0
          FAILURE_DETAILS="[]"
          if [[ -f test-failures-summary.json ]] && [[ -s test-failures-summary.json ]]; then
            AFFECTED_PACKAGES=$(jq 'length' test-failures-summary.json 2>/dev/null || echo "0")
            # Extract failure details for completion report
            FAILURE_DETAILS=$(jq '[.[] as $parent | $parent.failures[] | {
              Test: .Test,
              Package: $parent.Package,
              Duration: (.Elapsed // "unknown"),
              Output: ((.Output // "") | if length > 500 then .[0:500] + "..." else . end)
            }]' test-failures-summary.json 2>/dev/null || echo "[]")
          fi

          # Use jq to build JSON safely - no heredocs, no sed, no complex logic
          STATS_FILE="test-stats-${{ matrix.os }}-${{ matrix.go-version }}.json"

          jq -n \
            --arg name "${{ matrix.name }}" \
            --arg os "${{ matrix.os }}" \
            --arg version "${{ matrix.go-version }}" \
            --arg exit_code "$TEST_EXIT_CODE" \
            --argjson passed "$TEST_PASSED" \
            --arg status "${{ job.status }}" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --arg test_mode "$OUTPUT_MODE" \
            --argjson duration "$TEST_DURATION" \
            --argjson test_count "$TEST_COUNT" \
            --argjson benchmark_count "$BENCHMARK_COUNT" \
            --argjson total_failures "$TOTAL_FAILURES" \
            --argjson affected_packages "$AFFECTED_PACKAGES" \
            --argjson failure_details "$FAILURE_DETAILS" \
            --argjson output_size "$OUTPUT_SIZE" \
            --argjson race_enabled "$RACE_ENABLED" \
            --argjson coverage_enabled "$COVERAGE_ENABLED" \
            --arg loc_test_files "$LOC_TEST_FILES" \
            --arg loc_go_files "$LOC_GO_FILES" \
            --arg loc_total "$LOC_TOTAL" \
            --arg loc_date "$LOC_DATE" \
            '{
              name: $name,
              os: $os,
              go_version: $version,
              test_mode: $test_mode,
              duration_seconds: $duration,
              test_count: $test_count,
              benchmark_count: $benchmark_count,
              status: $status,
              test_exit_code: ($exit_code | tonumber),
              test_passed: $passed,
              total_failures: $total_failures,
              affected_packages: $affected_packages,
              failure_details: $failure_details,
              output_size_bytes: $output_size,
              race_enabled: $race_enabled,
              coverage_enabled: $coverage_enabled,
              fuzz_run: false,
              timestamp: $timestamp,
              loc_test_files: $loc_test_files,
              loc_go_files: $loc_go_files,
              loc_total: $loc_total,
              loc_date: $loc_date
            }' > "$STATS_FILE"

          echo "📊 Test statistics generated successfully:"
          jq . "$STATS_FILE"

      # ————————————————————————————————————————————————————————————————
      # Collect cache statistics
      # ————————————————————————————————————————————————————————————————
      - name: 📊 Collect cache statistics
        id: cache-stats
        if: always()
        uses: ./.github/actions/collect-cache-stats
        with:
          workflow-name: test-${{ matrix.os }}-${{ matrix.go-version }}
          job-name: test-go
          os: ${{ matrix.os }}
          go-version: ${{ matrix.go-version }}
          gomod-cache-hit: ${{ steps.setup-go-test.outputs.module-cache-hit }}
          gobuild-cache-hit: ${{ steps.setup-go-test.outputs.build-cache-hit }}

      # ————————————————————————————————————————————————————————————————
      # Upload cache statistics
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload cache statistics
        if: always()
        uses: ./.github/actions/upload-statistics
        with:
          artifact-name: cache-stats-test-${{ matrix.os }}-${{ matrix.go-version }}
          artifact-path: cache-stats-test-${{ matrix.os }}-${{ matrix.go-version }}.json
          retention-days: 1

      # ————————————————————————————————————————————————————————————————
      # Upload test artifacts
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload test outputs and statistics
        if: always()
        uses: ./.github/actions/upload-statistics
        with:
          artifact-name: test-results-${{ matrix.os }}-${{ matrix.go-version }}
          artifact-path: |
            test-stats-*.json
            test-failures*.json
            test-failures*.jsonl
            test-failures.txt
            test-output*.log
            test-raw-output.log
            test-json-output.log
            test-stderr.log
          retention-days: ${{ env.TEST_OUTPUT_ARTIFACT_RETENTION_DAYS || 7 }}
          compression-level: ${{ env.TEST_OUTPUT_COMPRESS_ARTIFACTS == 'true' && '9' || '0' }}

      # ————————————————————————————————————————————————————————————————
      # Upload test statistics (backward compatibility)
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload test statistics
        if: always()
        uses: ./.github/actions/upload-statistics
        with:
          artifact-name: test-stats-${{ matrix.os }}-${{ matrix.go-version }}
          artifact-path: test-stats-*.json
          retention-days: 1

      # ————————————————————————————————————————————————————————————————
      # Verify coverage file before upload
      # ————————————————————————————————————————————————————————————————
      - name: 🔍 Verify coverage file
        if: inputs.code-coverage-enabled == 'true'
        run: |
          if [ -f coverage.txt ]; then
            echo "✅ Coverage file exists"
            echo "📊 Coverage file size: $(wc -c < coverage.txt) bytes"
            echo "📊 Coverage file lines: $(wc -l < coverage.txt)"
            echo "📊 First line: $(head -1 coverage.txt)"
            echo "📊 Last line: $(tail -1 coverage.txt)"

            # Ensure the coverage file starts with valid coverage data
            FIRST_LINE=$(head -1 coverage.txt)
            if [[ "$FIRST_LINE" == "mode: atomic" ]] || [[ "$FIRST_LINE" == "mode: count" ]] || [[ "$FIRST_LINE" == "mode: set" ]]; then
              echo "✅ Coverage file format looks valid"

              # Additional debugging info
              echo "📋 Sample coverage lines (lines 2-5):"
              sed -n '2,5p' coverage.txt

              # Check for any non-ASCII characters
              if file coverage.txt | grep -q "ASCII text"; then
                echo "✅ File is pure ASCII text"
              else
                echo "⚠️ File may contain non-ASCII characters"
                file coverage.txt
              fi

              # Check file permissions
              echo "📋 File permissions: $(ls -la coverage.txt)"

              # List all coverage files in directory
              echo "📋 All coverage files in current directory:"
              ls -la *.txt *.out 2>/dev/null | grep -E "(coverage|cover)" || echo "No other coverage files found"

            else
              echo "❌ Coverage file may be corrupted. First line should be 'mode: atomic' or 'mode: count' but got: $FIRST_LINE"
              echo "📋 First 10 lines of coverage file:"
              head -10 coverage.txt
              exit 1
            fi
          else
            echo "❌ Coverage file not found!"
            echo "📋 Current directory: $(pwd)"
            echo "📋 Files in current directory:"
            ls -la
            exit 1
          fi

      # ————————————————————————————————————————————————————————————————
      # Upload coverage data for processing
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload coverage data
        if: inputs.code-coverage-enabled == 'true' && matrix.os == inputs.primary-runner && matrix.go-version == inputs.go-primary-version
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: coverage-data
          path: coverage.txt
          retention-days: 1

  # ----------------------------------------------------------------------------------
  # Fuzz Tests (Parallel)
  # ----------------------------------------------------------------------------------
  fuzz-tests:
    name: 🎯 Fuzz Tests
    if: inputs.fuzz-testing-enabled == 'true'
    timeout-minutes: 15 # Fuzz tests have shorter timeout
    permissions:
      contents: read # Read repository content for testing
    runs-on: ${{ inputs.primary-runner }}

    steps:
      # ————————————————————————————————————————————————————————————————
      # Checkout code (required for local actions)
      # ————————————————————————————————————————————————————————————————
      - name: 📥 Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      # ————————————————————————————————————————————————————————————————
      # Parse environment variables
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Parse environment variables
        uses: ./.github/actions/parse-env
        with:
          env-json: ${{ inputs.env-json }}

      # ————————————————————————————————————————————————————————————————
      # Setup Go with caching and version management (primary version only)
      # ————————————————————————————————————————————————————————————————
      - name: 🏗️ Setup Go with Cache
        id: setup-go-fuzz
        uses: ./.github/actions/setup-go-with-cache
        with:
          go-version: ${{ inputs.go-primary-version }}
          matrix-os: ${{ inputs.primary-runner }}
          go-primary-version: ${{ inputs.go-primary-version }}
          go-secondary-version: ${{ inputs.go-secondary-version }}

      # ————————————————————————————————————————————————————————————————
      # Setup MAGE-X (required for magex test commands)
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Setup MAGE-X
        uses: ./.github/actions/setup-magex
        with:
          magex-version: ${{ env.MAGE_X_VERSION }}
          runner-os: ${{ inputs.primary-runner }}

      # ————————————————————————————————————————————————————————————————
      # Start fuzz test timer
      # ————————————————————————————————————————————————————————————————
      - name: ⏱️ Start fuzz test timer
        id: fuzz-timer
        run: |
          echo "fuzz-start=$(date +%s)" >> $GITHUB_OUTPUT

      # ————————————————————————————————————————————————————————————————
      # Run fuzz tests
      # ————————————————————————————————————————————————————————————————
      - name: 🎯 Run fuzz tests
        id: run-fuzz-tests
        continue-on-error: true
        run: |
          echo "🎯 Running fuzz tests in parallel..."
          FUZZ_TIMEOUT="${TEST_TIMEOUT_FUZZ:-5m}"
          magex test:fuzz time=5s -timeout $FUZZ_TIMEOUT 2>&1 | tee fuzz-output.log
          FUZZ_EXIT_CODE=${PIPESTATUS[0]}
          echo "🔧 Fuzz tests completed with timeout: $FUZZ_TIMEOUT"

          # Store the exit code for later steps
          echo "FUZZ_EXIT_CODE=$FUZZ_EXIT_CODE" >> $GITHUB_ENV
          echo "fuzz-exit-code=$FUZZ_EXIT_CODE" >> $GITHUB_OUTPUT

          if [[ $FUZZ_EXIT_CODE -eq 0 ]]; then
            echo "✅ Fuzz tests completed successfully"
          else
            echo "❌ Fuzz tests failed with exit code $FUZZ_EXIT_CODE"
          fi

      # ————————————————————————————————————————————————————————————————
      # Fuzz test failure analysis and reporting
      # ————————————————————————————————————————————————————————————————
      - name: 🚨 Create Fuzz Test Failure Summary
        if: failure()
        run: |
          echo "## 🚨 Fuzz Test Failures" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **OS**: ${{ inputs.primary-runner }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Go Version**: ${{ inputs.go-primary-version }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f fuzz-output.log ]; then
            # Use robust failure detection for fuzz tests
            if command -v detect_failures_from_text >/dev/null 2>&1; then
              # Use robust detection if functions are available
              detect_failures_from_text "fuzz-output.log" "fuzz-failures.txt" || true
              FAIL_COUNT=$(wc -l < fuzz-failures.txt 2>/dev/null || echo "0")
              echo "🔍 Using robust fuzz failure detection: $FAIL_COUNT"
            else
              # Fallback: use enhanced patterns with numeric validation
              FAIL_COUNT=$(grep -c -E "^(FAIL|---[[:space:]]*FAIL|--[[:space:]]*FAIL|\[?FAIL\]?)[[:space:]:.]" fuzz-output.log 2>/dev/null || echo "0")
              FAIL_COUNT=$(echo "$FAIL_COUNT" | tr -d '\n\r' | xargs)
              [[ "$FAIL_COUNT" =~ ^[0-9]+$ ]] || FAIL_COUNT=0
              echo "⚠️ Using enhanced patterns for fuzz failure detection: $FAIL_COUNT"
            fi

            # Enhanced panic detection with numeric validation
            PANIC_COUNT=$(grep -c -E "panic:|fatal error:|runtime error:" fuzz-output.log 2>/dev/null || echo "0")
            PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
            [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0

            echo "- **Failed Fuzz Tests**: $FAIL_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "- **Panics**: $PANIC_COUNT" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ "$FAIL_COUNT" -gt 0 ]; then
              echo "### 🔍 Failed Fuzz Test Summary (First 5)" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              if [[ -f fuzz-failures.txt ]] && [[ -s fuzz-failures.txt ]]; then
                head -5 fuzz-failures.txt >> $GITHUB_STEP_SUMMARY
              else
                # Fallback: use enhanced patterns
                grep -E "^(FAIL|---[[:space:]]*FAIL|--[[:space:]]*FAIL|\[?FAIL\]?)[[:space:]:.]" fuzz-output.log | head -5 >> $GITHUB_STEP_SUMMARY
              fi
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            if [ "$PANIC_COUNT" -gt 0 ]; then
              echo "### 🚨 Fuzz Test Panic/Error Summary" >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
              # Enhanced panic/error detection patterns
              grep -A 2 -B 1 -E "panic:|fatal error:|runtime error:" fuzz-output.log | head -20 >> $GITHUB_STEP_SUMMARY
              echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "⚠️ Fuzz test output log not found" >> $GITHUB_STEP_SUMMARY
          fi

      - name: 📋 Annotate Key Fuzz Test Failures
        if: failure()
        run: |
          if [ -f fuzz-output.log ]; then
            echo "::group::📋 Fuzz Test Failure Analysis (Enhanced)"

            # Count and report overall statistics using robust detection
            if [[ -f fuzz-failures.txt ]] && [[ -s fuzz-failures.txt ]]; then
              FAIL_COUNT=$(wc -l < fuzz-failures.txt 2>/dev/null || echo "0")
              echo "🔍 Using robust fuzz failure count for annotation: $FAIL_COUNT"
            else
              # Fallback: use enhanced patterns with numeric validation
              FAIL_COUNT=$(grep -c -E "^(FAIL|---[[:space:]]*FAIL|--[[:space:]]*FAIL|\[?FAIL\]?)[[:space:]:.]" fuzz-output.log 2>/dev/null || echo "0")
              FAIL_COUNT=$(echo "$FAIL_COUNT" | tr -d '\n\r' | xargs)
              [[ "$FAIL_COUNT" =~ ^[0-9]+$ ]] || FAIL_COUNT=0
              echo "⚠️ Using enhanced patterns for fuzz annotation: $FAIL_COUNT"
            fi

            # Enhanced panic detection with numeric validation
            PANIC_COUNT=$(grep -c -E "panic:|fatal error:|runtime error:" fuzz-output.log 2>/dev/null || echo "0")
            PANIC_COUNT=$(echo "$PANIC_COUNT" | tr -d '\n\r' | xargs)
            [[ "$PANIC_COUNT" =~ ^[0-9]+$ ]] || PANIC_COUNT=0

            echo "::error title=Fuzz Test Suite Failed::$FAIL_COUNT fuzz tests failed, $PANIC_COUNT panics/errors detected on ${{ inputs.primary-runner }} Go ${{ inputs.go-primary-version }}"

            # Annotate first 3 failed fuzz tests using robust detection
            if [[ "$FAIL_COUNT" -gt 0 ]]; then
              if [[ -f fuzz-failures.txt ]] && [[ -s fuzz-failures.txt ]]; then
                head -3 fuzz-failures.txt | while IFS= read -r line; do
                  echo "::error title=Failed Fuzz Test::$line"
                done
              else
                # Fallback: use enhanced patterns
                grep -E "^(FAIL|---[[:space:]]*FAIL|--[[:space:]]*FAIL|\[?FAIL\]?)[[:space:]:.]" fuzz-output.log | head -3 | while IFS= read -r line; do
                  echo "::error title=Failed Fuzz Test::$line"
                done
              fi
            fi

            # Annotate panics/errors with enhanced patterns
            if [ "$PANIC_COUNT" -gt 0 ]; then
              grep -B 1 -E "panic:|fatal error:|runtime error:" fuzz-output.log | head -2 | while IFS= read -r line; do
                echo "::error title=Fuzz Test Panic/Error::$line"
              done
            fi

            echo "::endgroup::"
          fi

      # ————————————————————————————————————————————————————————————————
      # Calculate fuzz test statistics (simplified approach)
      # ————————————————————————————————————————————————————————————————
      - name: 📊 Calculate fuzz test statistics
        id: fuzz-summary
        if: always()
        run: |
          # Get basic values
          FUZZ_EXIT_CODE="${{ steps.run-fuzz-tests.outputs.fuzz-exit-code || '0' }}"
          FUZZ_END=$(date +%s)
          FUZZ_DURATION=$((FUZZ_END - ${{ steps.fuzz-timer.outputs.fuzz-start || '0' }}))

          # Count fuzz tests
          FUZZ_TEST_COUNT=$(find . -type f -name '*_test.go' \
            -not -path './vendor/*' \
            -not -path './third_party/*' \
            -not -path './testdata/*' \
            -exec grep -hE '^\s*func (\([^)]+\) )?Fuzz[A-Z0-9_]' {} + | wc -l | xargs)
          FUZZ_TEST_COUNT=${FUZZ_TEST_COUNT:-0}

          # Pre-compute boolean values
          FUZZ_PASSED=$([ "$FUZZ_EXIT_CODE" = "0" ] && echo "true" || echo "false")

          # Use jq to build JSON safely - no heredocs, no complex logic
          FUZZ_STATS_FILE="fuzz-stats-${{ inputs.primary-runner }}-${{ inputs.go-primary-version }}.json"

          jq -n \
            --arg name "Fuzz Tests (${{ inputs.primary-runner }})" \
            --arg os "${{ inputs.primary-runner }}" \
            --arg version "${{ inputs.go-primary-version }}" \
            --arg exit_code "$FUZZ_EXIT_CODE" \
            --argjson passed "$FUZZ_PASSED" \
            --arg status "${{ job.status }}" \
            --arg timestamp "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --argjson duration "$FUZZ_DURATION" \
            --argjson fuzz_count "$FUZZ_TEST_COUNT" \
            '{
              name: $name,
              os: $os,
              go_version: $version,
              duration_seconds: $duration,
              fuzz_test_count: $fuzz_count,
              status: $status,
              fuzz_exit_code: ($exit_code | tonumber),
              fuzz_passed: $passed,
              fuzz_enabled: true,
              timestamp: $timestamp
            }' > "$FUZZ_STATS_FILE"

          echo "📊 Fuzz test statistics generated successfully:"
          jq . "$FUZZ_STATS_FILE"

      # ————————————————————————————————————————————————————————————————
      # Collect cache statistics
      # ————————————————————————————————————————————————————————————————
      - name: 📊 Collect cache statistics
        id: cache-stats-fuzz
        if: always()
        uses: ./.github/actions/collect-cache-stats
        with:
          workflow-name: fuzz
          job-name: fuzz-tests
          os: ${{ inputs.primary-runner }}
          go-version: ${{ inputs.go-primary-version }}
          gomod-cache-hit: ${{ steps.setup-go-fuzz.outputs.module-cache-hit }}
          gobuild-cache-hit: ${{ steps.setup-go-fuzz.outputs.build-cache-hit }}

      # ————————————————————————————————————————————————————————————————
      # Upload cache statistics
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload cache statistics
        if: always()
        uses: ./.github/actions/upload-statistics
        with:
          artifact-name: cache-stats-fuzz
          artifact-path: cache-stats-fuzz.json
          retention-days: 1

      # ————————————————————————————————————————————————————————————————
      # Upload fuzz test statistics
      # ————————————————————————————————————————————————————————————————
      - name: 📤 Upload fuzz test statistics
        if: always()
        uses: ./.github/actions/upload-statistics
        with:
          artifact-name: fuzz-stats-${{ inputs.primary-runner }}-${{ inputs.go-primary-version }}
          artifact-path: fuzz-stats-*.json
          retention-days: 1

  # ----------------------------------------------------------------------------------
  # Validate Test Results
  # ----------------------------------------------------------------------------------
  validate-test-results:
    name: 🔍 Validate Test Results
    needs: [test-go, fuzz-tests]
    if: always() # Always run to check results even if jobs continued on error
    permissions:
      contents: read # Read repository content for validation
    runs-on: ${{ inputs.primary-runner }}

    steps:
      # ————————————————————————————————————————————————————————————————
      # Checkout code (required for local actions)
      # ————————————————————————————————————————————————————————————————
      - name: 📥 Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0

      # ————————————————————————————————————————————————————————————————
      # Parse environment variables
      # ————————————————————————————————————————————————————————————————
      - name: 🔧 Parse environment variables
        uses: ./.github/actions/parse-env
        with:
          env-json: ${{ inputs.env-json }}

      # ————————————————————————————————————————————————————————————————
      # Download all test result artifacts (including failure details)
      # ————————————————————————————————————————————————————————————————
      - name: 📥 Download test results and statistics
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
        with:
          pattern: "test-results-*"
          path: test-results/
          merge-multiple: true

      - name: 📥 Download test statistics
        uses: actions/download-artifact@634f93cb2916e3fdff6788551b99b062d0335ce0 # v5.0.0
        with:
          pattern: "*-stats-*"
          path: test-results/
          merge-multiple: true

      # ————————————————————————————————————————————————————————————————
      # Enhanced test results validation with failure details
      # ————————————————————————————————————————————————————————————————
      - name: 🔍 Validate test results
        run: |
          echo "🔍 Validating test results from enhanced statistics..."
          VALIDATION_FAILED=false
          TOTAL_FAILURES=0
          TOTAL_TESTS=0

          # Check regular test results
          if compgen -G "test-results/test-stats-*.json" >/dev/null 2>&1; then
            echo "📋 Found test statistics files:"
            ls -la test-results/test-stats-*.json

            for stats_file in test-results/test-stats-*.json; do
              echo "📊 Checking $stats_file..."

              # Extract enhanced test results
              TEST_PASSED=$(jq -r '.test_passed // empty' "$stats_file")
              TEST_EXIT_CODE=$(jq -r '.test_exit_code // empty' "$stats_file")
              TEST_NAME=$(jq -r '.name // empty' "$stats_file")
              TEST_MODE=$(jq -r '.test_mode // "unknown"' "$stats_file")
              SUITE_FAILURES=$(jq -r '.total_failures // 0' "$stats_file")
              AFFECTED_PACKAGES=$(jq -r '.affected_packages // 0' "$stats_file")
              TEST_COUNT=$(jq -r '.test_count // 0' "$stats_file")

              echo "  • Test Suite: $TEST_NAME"
              echo "  • Mode: $TEST_MODE"
              echo "  • Tests: $TEST_COUNT"
              echo "  • Exit Code: $TEST_EXIT_CODE"
              echo "  • Passed: $TEST_PASSED"

              if [[ "$TEST_PASSED" == "false" ]] || [[ "$TEST_EXIT_CODE" != "0" ]]; then
                echo "  • Failed Tests: $SUITE_FAILURES"
                echo "  • Affected Packages: $AFFECTED_PACKAGES"

                # Show specific failure details if available
                FAILURE_DETAILS=$(jq -r '.failure_details // null' "$stats_file")
                if [[ "$FAILURE_DETAILS" != "null" ]] && [[ "$FAILURE_DETAILS" != "[]" ]]; then
                  echo "  • Failed Test Names:"
                  echo "$FAILURE_DETAILS" | jq -r '.[] | "    - \(.Test) (\(.Package | split("/") | .[-1] // .[-2] // .))"' 2>/dev/null | head -5 || true
                fi

                echo "❌ Test suite '$TEST_NAME' failed with exit code $TEST_EXIT_CODE ($SUITE_FAILURES failures)"
                VALIDATION_FAILED=true
                TOTAL_FAILURES=$((TOTAL_FAILURES + SUITE_FAILURES))
              else
                echo "✅ Test suite '$TEST_NAME' passed"
              fi

              TOTAL_TESTS=$((TOTAL_TESTS + TEST_COUNT))
            done
          else
            echo "⚠️ No regular test statistics found"
          fi

          # Check fuzz test results if enabled
          if [[ "${{ inputs.fuzz-testing-enabled }}" == "true" ]]; then
            if compgen -G "test-results/fuzz-stats-*.json" >/dev/null 2>&1; then
              echo "📋 Found fuzz test statistics files:"
              ls -la test-results/fuzz-stats-*.json

              for stats_file in test-results/fuzz-stats-*.json; do
                echo "📊 Checking $stats_file..."

                # Extract fuzz test results
                FUZZ_PASSED=$(jq -r '.fuzz_passed // empty' "$stats_file")
                FUZZ_EXIT_CODE=$(jq -r '.fuzz_exit_code // empty' "$stats_file")
                FUZZ_NAME=$(jq -r '.name // empty' "$stats_file")

                echo "  • Fuzz Test: $FUZZ_NAME"
                echo "  • Exit Code: $FUZZ_EXIT_CODE"
                echo "  • Passed: $FUZZ_PASSED"

                if [[ "$FUZZ_PASSED" == "false" ]] || [[ "$FUZZ_EXIT_CODE" != "0" ]]; then
                  echo "❌ Fuzz test suite '$FUZZ_NAME' failed with exit code $FUZZ_EXIT_CODE"
                  VALIDATION_FAILED=true
                else
                  echo "✅ Fuzz test suite '$FUZZ_NAME' passed"
                fi
              done
            else
              echo "⚠️ No fuzz test statistics found (fuzz testing was enabled)"
            fi
          fi

          # Enhanced validation summary
          echo ""
          echo "🏁 Validation Summary:"
          echo "  • Total Tests: $TOTAL_TESTS"
          echo "  • Total Failures: $TOTAL_FAILURES"

          # Display detailed failure information if tests failed
          if [[ "$VALIDATION_FAILED" == "true" ]]; then
            echo ""
            echo "🔍 Detailed Failure Analysis:"
            echo "==============================================="

            # Look for failure details in downloaded artifacts
            if compgen -G "test-results/test-failures-summary.json" >/dev/null 2>&1; then
              echo "📋 Found structured failure details:"
              for failure_file in test-results/test-failures-summary.json; do
                echo ""
                echo "📄 Processing: $failure_file"

                # Extract and display package-level failures
                PACKAGES=$(jq -r 'length' "$failure_file" 2>/dev/null || echo "0")
                if [[ "$PACKAGES" -gt 0 ]]; then
                  echo "  • Affected Packages: $PACKAGES"

                  # Show package summary
                  jq -r '.[] | "  📦 \(.Package | split("/") | .[-1] // .[-2] // .): \(.failures | length) failure(s)"' "$failure_file" 2>/dev/null || true

                  echo ""
                  echo "🚨 Failed Tests:"
                  echo "---------------"

                  # Show detailed failed tests with package context (leaf failures only)
                  #
                  # Problem: Go's nested test structure (TestA/TestB/TestC) reports failures for
                  # all parent tests when a leaf test fails, causing confusing output like:
                  #   ❌ TestNetworkEdgeCases/concurrent_api_operations/concurrency_3 (integration) <- actual failure
                  #   ❌ TestNetworkEdgeCases/concurrent_api_operations (integration)              <- parent (redundant)
                  #   ❌ TestNetworkEdgeCases (integration)                                       <- parent (redundant)
                  #   ❌  (integration)                                                           <- empty (artifact)
                  #
                  # Solution: Extract and deduplicate to show only the actual failed leaf tests
                  # This reduces "4 failures" to "1 actual failure" for better clarity.
                  RAW_FAILED_TESTS=$(jq -r '.[] as $parent | $parent.failures[] | .Test + " (" + ($parent.Package | split("/") | .[-1] // .[-2] // .) + ")"' "$failure_file" 2>/dev/null)

                  # Smart filtering: Only show the most specific (deepest nested) test failures
                  FAILED_TESTS=$(echo "$RAW_FAILED_TESTS" | awk '
                    {
                      # Skip empty lines
                      if ($0 == "" || $0 ~ /^[[:space:]]*$/) next

                      # Extract test name before package info
                      if (match($0, /^([^(]*[^[:space:]]) \(.*\)$/)) {
                        testname = substr($0, RSTART, RLENGTH)
                        gsub(/ \(.*\)$/, "", testname)
                        # Remove leading/trailing whitespace
                        gsub(/^[[:space:]]+|[[:space:]]+$/, "", testname)
                        # Skip if testname is empty
                        if (testname == "") next

                        # Count depth by number of "/" characters
                        depth_counter = testname
                        gsub(/[^\/]/, "", depth_counter)
                        depth = length(depth_counter)
                        tests[NR] = $0
                        depths[NR] = depth
                        names[NR] = testname
                      }
                    }
                    END {
                      # For each test, check if there is a more specific (deeper) version
                      for (i in tests) {
                        is_leaf = 1
                        for (j in tests) {
                          if (i != j && depths[j] > depths[i] && index(names[j], names[i]) == 1) {
                            is_leaf = 0
                            break
                          }
                        }
                        if (is_leaf && names[i] != "") print tests[i]
                      }
                    }
                  ' | head -20)

                  if [[ -n "$FAILED_TESTS" ]]; then
                    echo "$FAILED_TESTS" | sed 's/^/  ❌ /'

                    # Update failure count to reflect actual unique failures
                    ACTUAL_UNIQUE_FAILURES=$(echo "$FAILED_TESTS" | grep -v '^[[:space:]]*$' | wc -l)
                    RAW_FAILURE_COUNT=$(echo "$RAW_FAILED_TESTS" | grep -v '^[[:space:]]*$' | wc -l)
                    if [[ $RAW_FAILURE_COUNT -gt $ACTUAL_UNIQUE_FAILURES ]]; then
                      echo ""
                      echo "  📊 Note: Showing $ACTUAL_UNIQUE_FAILURES actual failures"
                      echo "         (filtered from $RAW_FAILURE_COUNT nested test hierarchy entries)"
                    fi
                  else
                    echo "  ⚠️ No test failures found in JSON structure"
                    echo "  📄 Raw JSON content:"
                    head -c 2000 "$failure_file" | sed 's/^/  /'
                  fi

                  # Show any error outputs if available from the enhanced failure details
                  ERROR_OUTPUTS=$(jq -r '.[] as $package | $package.failures[] | select(.Output and .Output != "" and .Output != null) | "❌ \(.Test) (\($package.Package | split("/") | .[-1] // .[-2] // .))\n\(.Output)\n"' "$failure_file" 2>/dev/null | head -c 3000)
                  if [[ -n "$ERROR_OUTPUTS" ]]; then
                    echo ""
                    echo "📝 Test Error Messages:"
                    echo "----------------------"
                    echo "$ERROR_OUTPUTS"
                  fi
                else
                  echo "  • No structured failure data found in JSON"
                fi
              done

            # Fallback to simple text files if JSON not available
            elif compgen -G "test-results/test-failures.txt" >/dev/null 2>&1; then
              echo "📋 Found text failure details:"
              for failure_file in test-results/test-failures.txt; do
                if [[ -s "$failure_file" ]]; then
                  echo ""
                  echo "📄 Processing: $failure_file"
                  echo "🚨 Failed Tests:"
                  echo "---------------"
                  head -20 "$failure_file" | while IFS= read -r line; do
                    echo "  ❌ $line"
                  done
                fi
              done

            else
              echo "⚠️ No detailed failure information found in downloaded artifacts"
              echo "   Available files:"
              ls -la test-results/ 2>/dev/null | head -10 || echo "   No files found"
            fi

            echo ""
            echo "==============================================="
            echo "❌ Test validation failed - $TOTAL_FAILURES test(s) failed across all suites"
            echo "::error title=Test Validation Failed::$TOTAL_FAILURES test(s) failed across all test suites. Check enhanced failure details above."
            exit 1
          else
            echo "✅ All $TOTAL_TESTS tests passed validation"
          fi

  # ----------------------------------------------------------------------------------
  # Process Coverage
  # ----------------------------------------------------------------------------------
  process-coverage:
    name: 📊 Process Coverage
    needs: [test-go, validate-test-results]
    if: inputs.code-coverage-enabled == 'true' && !startsWith(github.ref, 'refs/tags/')
    permissions:
      contents: write # Write repository content and push to gh-pages branch for coverage processing
      pull-requests: write # Required: Coverage workflow needs to create PR comments
      pages: write # Required: Coverage workflow needs to deploy to GitHub Pages
      id-token: write # Required: Coverage workflow needs GitHub Pages authentication
      statuses: write # Required: Coverage workflow needs to create commit status checks
    uses: ./.github/workflows/fortress-coverage.yml
    with:
      coverage-file: coverage.txt
      branch-name: ${{ github.head_ref || github.ref_name }}
      commit-sha: ${{ github.sha }}
      env-json: ${{ inputs.env-json }}
      primary-runner: ${{ inputs.primary-runner }}
      event-name: ${{ github.event_name }}
      pr-number: ${{ github.event.pull_request.number }}
    secrets:
      github-token: ${{ secrets.GH_PAT_TOKEN != '' && secrets.GH_PAT_TOKEN || secrets.GITHUB_TOKEN }}
      CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
